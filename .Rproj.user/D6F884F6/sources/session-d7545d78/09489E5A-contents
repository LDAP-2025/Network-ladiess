# Load Data and Dependencies ----------------------------------------------

library(dplyr) # for data manipulation
library(ggplot2) # for graphing
library(lme4) # for multilevel models
library(lmerTest) # for p-values

data <- read.csv('heck2011 copy 4.csv', fileEncoding = "UTF-8-BOM")

# Introduction to Estimation Problems -------------------------------------

ses_l1_random <- lmer(math ~ 1 + ses + (1 + ses|schcode), data = data, REML = TRUE)

# Estimation and Optimizers -----------------------------------------------

#In multilevel modelling, we use maximum likelihood (ML) estimation instead of OLS estimation. In ML estimation, we have our data points and we want to find the combination of parameters (intercepts and slopes) that maximize the likelihood that we observed that data. This is an iterative process, where we select parameters that maximize the probability of getting our data (i.e., that maximize the likelihood) optimization algorithms (AKA optimizers) are used to try to find the ML estimates by examining a subset of possible combinations

data %>% 
  filter(schcode <= 10) %>% # subset data to make it easier to see
  ggplot(mapping = aes(x = ses, y = math)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE)

# Singularity -------------------------------------------------------------
#Singularity occurs when an element of your variance-covariance matrix is estimated as essentially zero as a result of extreme multicollinearity or because the parameter is actually essentially zero.

ses_l1_random <- lmer(math ~ 1 + ses + (1 + ses|schcode), data = data, REML = TRUE)

Matrix::bdiag(VarCorr(ses_l1_random))

summary(ses_l1_random)

confint(ses_l1_random, oldNames = FALSE)

ses_l1_random_cov0 <- lmer(math ~ 1 + ses + (1|schcode) + (0 + ses|schcode), data = data, REML = TRUE)
summary(ses_l1_random_cov0)

Matrix::bdiag(VarCorr(ses_l1_random_cov0))

# Deviance Testing for Model Comparison -----------------------------------

ses_l1 <- lmer(math ~ 1 + ses + (1|schcode), data = data, REML = TRUE)
ses_l1_random_cov0 <- lmer(math ~ 1 + ses + (1|schcode) + (0 + ses|schcode), data = data, REML = TRUE)

# deviance test to compare model fit
anova(ses_l1, ses_l1_random_cov0, refit = FALSE)

#Parameter interpretation
#npar is the number of parameters estimated in the models. The only difference between the models is one has a random slope for SES and the other doesn’t, and you can see that one model estimates 4 parameters and the other 5 parameters.
#AIC: Akaike’s Information Criterion, one measure of goodness of fit
#BIC: Bayesian Information Criterion, another measure of goodness of fit
#logLik: log likelihood
#deviance: -2*logLik
#Chisq: the difference betwen our models’ deviances
#df: the degrees of freedom for the test, calculated as the difference in number of parameters between the models
#Pr(>Chisq): the probability that we would find our chi-square value or greater if the null hypothesis that the models were the same was true

# there is no significant different in model fits and adding a random slope does not compromise model fit so we can add it if we think it’s informative.
